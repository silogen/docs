model,tokenizer,tensor-parallel-size,input-len,output-len,num-prompts,max-num-seqs,max-seq-len-to-capture,max-num-batched-tokens,max-model-len,gpu-memory-utilization,num-scheduler-steps,enable-chunked-prefill,distributed-executor-backend,kv-cache-dtype,dtype,export VLLM_FP8_PADDING,export VLLM_FP8_ACT_PADDING,export VLLM_FP8_WEIGHT_PADDING,export VLLM_FP8_REDUCE_CONV,export NCCL_MIN_NCHANNELS,export HIP_FORCE_DEV_KERNARG,export VLLM_USE_TRITON_FLASH_ATTN
Qwen/Qwen2.5-0.5B-Instruct,Qwen/Qwen2.5-0.5B-Instruct,1,128,1,1000,4000,131072,131072,8192,0.9,10,=False,mp,fp8,float16,1,1,1,1,112,1,0
