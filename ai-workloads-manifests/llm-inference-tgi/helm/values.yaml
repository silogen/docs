metadata:
  labels: {}

image: "ghcr.io/huggingface/text-generation-inference:3.0.2-rocm"
imagePullPolicy: Always

model: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
gpus: 1
memory_per_gpu: 64 # Gi
cpu_per_gpu: 4

# tgi engine args (ref: https://huggingface.co/docs/text-generation-inference/reference/launcher)
tgi_engine_args:
  {}
  # model-id: "{{ .Values.model }}"  # taken care of by the template
  # num-shard: {{ .Values.gpus }}  # taken care of by the template

# env vars ()
env_vars:
  BUCKET_STORAGE_HOST: https://default-minio-tenant-hl.minio-tenant-default.svc.cluster.local:9000
  BUCKET_STORAGE_ACCESS_KEY:
    name: minio-credentials
    key: minio-access-key
  BUCKET_STORAGE_SECRET_KEY:
    name: minio-credentials
    key: minio-secret-key
  HF_HOME: /workload/.cache/huggingface
  PYTORCH_TUNABLEOP_ENABLED: "0"

storage:
  ephemeral:
    quantity: 128Gi
    storageClassName: mlstorage
    accessModes:
      - ReadWriteOnce
  dshm:
    sizeLimit: 32Gi

deployment:
  ports:
    http: 8080

# startupProbe - checks if the container has successfully started. It disables liveness and readiness probes until it succeeds, useful for slow-starting applications.
# livenessProbe - checks if the container is still alive. If it fails, Kubernetes restarts the container to recover from failure.
# readinessProbe - checks if the container is ready to serve traffic. If it fails, the container is removed from the service's endpoints but remains running.
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
startupProbe:
  httpGet:
    path: /v1/models
    port: http
  periodSeconds: 10
  failureThreshold: 360 # 360 x 10s => allow for 60 minutes startup time
livenessProbe:
  httpGet:
    path: /
    port: http
readinessProbe:
  httpGet:
    path: /
    port: http

# kaiwo settings (if enabled, use kaiwo CRDs to have kaiwo operator manage the workload)
kaiwo:
  enabled: false
