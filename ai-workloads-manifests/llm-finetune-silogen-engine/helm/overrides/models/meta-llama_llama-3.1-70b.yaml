# To use this with the Llama 3.1 70B downloaded with the workload workloads/download-huggingface-model-to-bucket/helm
# and the override file workloads/download-huggingface-model-to-bucket/helm/overrides/llama-3.1-70b-to-minio.yaml
# Specify: --set basemodel=default-bucket/models/meta-llama/Llama-3.1-70B in your helm template command.
finetuningImage: ghcr.io/silogen/rocm-silogen-finetuning-worker:v0.5

# Resources:
downloadsReservedSize: 160Gi
checkpointsReservedSize: 160Gi
finetuningGpus: 8
memoryPerGpu: 192
cpuPerGpu: 8

# Runtime configuration:
distributedType: "auto-deepspeed-stage3"

### Finetuning config section ###
finetuning_config:
  method: sft
  data_conf:
    training_data:
      type: CONCATENATION
      datasets:
        - path: "PLACEHOLDER"
    validation_data:
      type: AUTO_SPLIT
      ratio: 0.1
    chat_template_name: "simplified-llama31"
    missing_pad_token_strategy: "bos-repurpose"
  training_args:
    learning_rate: 0.000005
    max_grad_norm: 1.0
    weight_decay: 0.000001
    optim: "adamw_torch"
    num_train_epochs: 1
    lr_scheduler_type: cosine
    warmup_ratio: 0.01
    logging_strategy: steps
    logging_steps: 0.01
    save_strategy: "no"
    seed: 42
    bf16: true
    push_to_hub: false
    gradient_checkpointing: true
    gradient_checkpointing_kwargs:
      use_reentrant: true
    eval_steps: 0.2
    eval_strategy: "steps"
    metric_for_best_model: "loss"
    greater_is_better: false
    load_best_model_at_end: false
  batchsize_conf:
    max_per_device_train_batch_size: 1
  peft_conf:
    peft_type: "NO_PEFT"
  run_conf:
    model_args:
      torch_dtype: bfloat16
      use_cache: false
      attn_implementation: "flash_attention_2"
    resume_from_checkpoint: auto
  sft_args:
    max_seq_length: 4096
