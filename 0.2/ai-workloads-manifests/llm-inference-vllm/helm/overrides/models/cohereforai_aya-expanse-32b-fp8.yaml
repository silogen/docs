model: CohereForAI/aya-expanse-32b
vllm_engine_args:
  quantization: fp8
