site_name: AMD Resource Manager & AMD AI Workbench documentation
site_description: Documentation for AMD Resource Manager & AMD AI Workbench
repo_url: https://github.com/silogen/docs
docs_dir: docs

theme:
  icon: material/developer-board
  logo: media/logo.svg
  name: material
  palette:
    # Palette toggle for automatic mode
    - media: "(prefers-color-scheme)"
      primary: black
      accent: black
      toggle:
        icon: material/brightness-auto
        name: Switch to light mode

    # Palette toggle for light mode
    - media: "(prefers-color-scheme: light)"
      scheme: default
      primary: black
      accent: black
      toggle:
        icon: material/brightness-7
        name: Switch to dark mode

    # Palette toggle for dark mode
    - media: "(prefers-color-scheme: dark)"
      scheme: slate
      primary: black
      accent: black
      toggle:
        icon: material/brightness-4
        name: Switch to system preference

  features:
    - content.code.copy
    - navigation.indexes
    - navigation.tabs
    - navigation.top
    - search.highlight
    - search.suggest

plugins:
  - search
  - tags
  - macros

  - redirects:
      redirect_maps:
        'core/docs/workbench/inference/index.md': 'core/docs/workbench/inference/overview.md'
        'core/docs/workbench/training/index.md': 'core/docs/workbench/training/overview.md'
        'core/docs/resource-manager/index.md': 'core/docs/resource-manager/overview.md'
        'core/docs/resource-manager/clusters/index.md': 'core/docs/resource-manager/clusters/overview.md'
        'core/docs/resource-manager/projects/index.md': 'core/docs/resource-manager/projects/manage-projects.md'
        'core/docs/resource-manager/users/index.md': 'core/docs/resource-manager/users/overview.md'
        'platform-infrastructure/index.md': 'platform-infrastructure/supported-environments.md'
        'references/index.md': 'references/overview.md'

        # Change this to link to an external feedback page.
        # 'feedback.md': 'feedback-url.here'

markdown_extensions:
  - pymdownx.highlight:
      anchor_linenums: true
  - pymdownx.superfences
  - pymdownx.inlinehilite
  - pymdownx.tabbed
  - pymdownx.snippets:
      base_path: !relative $docs_dir
  - admonition
  - footnotes
  - attr_list
  - toc:
      permalink: true

nav:
  - Introduction:
    - Home: index.md
    - Platform Overview: platform-overview.md
    - Target Audience: target-audience.md
    - Quick Start Guide: quick-start.md
    - General Topics:
      - Login to the Platform: login.md
      - Personal Preferences: personal-preferences.md
    - Release Notes: release-notes.md

  - Infrastructure Administrator:
    - Installation:
      - Supported Environments: platform-infrastructure/supported-environments.md
      - On-premises Installation: platform-infrastructure/on-premises-installation.md
      - DigitalOcean Cloud Installation: platform-infrastructure/digitalocean-installation.md

  - AI Practitioner:
    - AMD AI Workbench Overview: core/docs/workbench/overview.md
    - Quick Start for AI Practitioners: quick-start-guides/workbench-quick-start.md
    - Workspaces: core/docs/workbench/workspaces.md
    - Workloads: core/docs/workbench/workloads.md

    - Training and Fine-tuning:
      - Fine-tuning: core/docs/workbench/training/fine-tuning.md
      - Models: core/docs/workbench/training/models.md
      - Datasets: core/docs/workbench/training/datasets.md

    - Inference:
      - Inference Overview: core/docs/workbench/inference/overview.md
      - Chat with Models: core/docs/workbench/inference/chat.md
      - Compare Models: core/docs/workbench/inference/compare.md

    - Tutorials:
      - GUI Access:
        - Low-code Fine-tuning Tutorial: tutorials/low-code-fine-tuning-tutorial.md
        - AI Workspace Tutorial: tutorials/ai-workspace-tutorial.md
        - Deploy a Model and Run Inference: core/docs/workbench/inference/how-to-deploy-and-inference.md
      - CLI Access:
        - CLI Tutorials Overview: cli-tutorials-overview.md
        - Prerequisites for Running the Tutorials: ai-workloads-docs/tutorials/tutorial-00-prerequisites.md
        - Deliver Resources and Fine-tune: ai-workloads-docs/tutorials/tutorial-01-deliver-resources-and-finetune.md
        - Language Extension - Odia Fine-tuning: ai-workloads-docs/tutorials/tutorial-02-language-extension-finetune.md
        - Continuous Pretraining of Llama-3.1-8B: ai-workloads-docs/tutorials/tutorial-03-deliver-resources-and-run-megatron-cpt.md
        - Continuous Pretraining of Llama-3.1-70B: ai-workloads-docs/tutorials/tutorial-04-deliver-llama70b-and-run-megatron-cpt-with-tp8-ddp2.md

    - Reference AI Workloads:
      - Workloads Overview: ai-workloads-manifests/workloads-overview.md
      - dev-chatui-openwebui: ai-workloads-manifests/dev-chatui-openwebui/helm/README.md
      - dev-openvscode-server: ai-workloads-manifests/dev-workspace-vscode/helm/README.md
      - dev-text2image-comfyui: ai-workloads-manifests/dev-text2image-comfyui/helm/README.md
      - download-data-to-bucket: ai-workloads-manifests/download-data-to-bucket/helm/README.md
      - download-huggingface-model-to-bucket: ai-workloads-manifests/download-huggingface-model-to-bucket/helm/README.md
      - k8s-namespace-setup: ai-workloads-manifests/k8s-namespace-setup/helm/README.md
      - llm-finetune-silogen-engine:
        - LLM fine-tuning overview: ai-workloads-manifests/llm-finetune-silogen-engine/helm/README.md
        - Fine-tuning config: ai-workloads-manifests/llm-finetune-silogen-engine/helm/silogen_finetuning_config_readme.md
      - llm-inference-llamacpp-mi300x: ai-workloads-manifests/llm-inference-llamacpp-mi300x/helm/README.md
      - llm-inference-sglang: ai-workloads-manifests/llm-inference-sglang/helm/README.md
      - llm-inference-vllm: ai-workloads-manifests/llm-inference-vllm/helm/README.md
      - llm-inference-vllm-benchmark-mad: ai-workloads-manifests/llm-inference-vllm-benchmark-mad/helm/README.md

  - AI Resource Manager:
    - AMD Resource Manager Overview: core/docs/resource-manager/overview.md
    - Quick Start for AI Resource Managers: quick-start-guides/resource-manager-quick-start.md
    - Dashboard: core/docs/resource-manager/dashboard.md
    - Clusters:
      - Clusters Overview: core/docs/resource-manager/clusters/overview.md
    - Projects:
      - Projects Overview: core/docs/resource-manager/projects/manage-projects.md
      - Project Dashboard: core/docs/resource-manager/projects/project-dashboard.md
      - Project Quotas: core/docs/resource-manager/projects/project-quotas.md
    - User Management:
      - Users Overview: core/docs/resource-manager/users/overview.md
      - Set up User Management:
        - Enable Single Sign-on: core/docs/keycloak/sso.md
        - Configure SMTP and Invite Users: core/docs/keycloak/smtp-configuration.md
        - Add Users Manually: core/docs/keycloak/manual-user-management.md
      - Manage Users: core/docs/resource-manager/users/manage-users.md
    - Tutorials:
        - Resource Utilization: tutorials/resource-utilization.md

  - References:
    - References: references/overview.md
    - Tags: references/tags.md

extra:
  name: AMD Resource Manager & AMD AI Workbench
  name_secondary: AMD Enterprise AI platform

extra_css:
  - stylesheets/extra.css

exclude_docs: |
  ref-architecture/AMDEnterpriseAISuite.md
  ref-architecture/Enterprise-AI-Architecture.md

  references/contributing.md

  core/docs/resource-manager/clusters/add-clusters-ui.md

  # Imported files
  ai-workloads-docs/contributing.md
  ai-workloads-docs/getting-started.md
  ai-workloads-docs/tutorials.md
  ai-workloads-docs/workloads.md
  ai-workloads-manifests/dev-chatui-aiaio/helm/mount/README.md
  ai-workloads-manifests/dev-chatui-openwebui/helm/mount/README.md
  ai-workloads-manifests/dev-text2image-comfyui/helm/mount/README.md
  ai-workloads-manifests/dev-workspace-jupyterlab/helm/mount/README.md
  ai-workloads-manifests/dev-workspace-vscode/helm/mount/README.md
  ai-workloads-manifests/llm-inference-llamacpp-mi300x/helm/mount/README.md
  ai-workloads-manifests/llm-inference-ollama/helm/mount/README.md
  ai-workloads-manifests/llm-inference-openai-benchmark-guidellm/helm/mount/README.md
  ai-workloads-manifests/llm-inference-openai-benchmark-rocmblog/helm/mount/README.md
  ai-workloads-manifests/llm-inference-sglang/helm/mount/README.md
  ai-workloads-manifests/llm-inference-tgi/helm/mount/README.md
  ai-workloads-manifests/llm-inference-vllm-benchmark-mad/helm/mount/README.md
  ai-workloads-manifests/llm-inference-vllm-benchmark-rocmblog/helm/mount/README.md
  ai-workloads-manifests/llm-inference-vllm/helm/mount/README.md
  ai-workloads-manifests/llm-pretraining-megatron-lm/helm/mount/README.md
  ai-workloads-manifests/rag-embedding-infinity/helm/mount/README.md
